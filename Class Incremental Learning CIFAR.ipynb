{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x1LgYbOF0mLC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "NY9e70dM0qh8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd_ZAKdQ0v73",
        "outputId": "4af5a4a5-0a12-49cf-9079-7ae789cbfe4b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "device = \"cuda:0\""
      ],
      "metadata": {
        "id": "rHG2dpoH0wYw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet50(nn.Module):\n",
        "    def __init__(self, hidden_units, out_size):\n",
        "        super(ResNet50, self).__init__()\n",
        "        self.resnet50 = models.resnet50(pretrained=True)\n",
        "        self.resnet50.fc_layer = nn.Linear(2048, hidden_units)\n",
        "        self.resnet50.classifier = nn.Linear(hidden_units, out_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.resnet50.conv1(x)\n",
        "        features = self.resnet50.bn1(features)\n",
        "        features = self.resnet50.relu(features)\n",
        "        features = self.resnet50.maxpool(features)\n",
        "        features = self.resnet50.layer1(features)\n",
        "        features = self.resnet50.layer2(features)\n",
        "        features = self.resnet50.layer3(features)\n",
        "        fmaps_b4 = self.resnet50.layer4(features)\n",
        "        out = F.adaptive_avg_pool2d(fmaps_b4, (1, 1)).view(fmaps_b4.size(0), -1)\n",
        "        out = self.resnet50.fc_layer(out)\n",
        "        out = self.resnet50.classifier(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "9owi_koN0zJS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = ResNet50(hidden_units=128, out_size=2).to(device)"
      ],
      "metadata": {
        "id": "iNuLkd9701aK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_indices = [0,1]\n",
        "train_dataset_1 = torch.utils.data.Subset(train_dataset, [i for i in range(len(train_dataset)) if train_dataset.targets[i] in class_indices])\n",
        "test_dataset_1 = torch.utils.data.Subset(train_dataset, [i for i in range(len(train_dataset)) if train_dataset.targets[i] in class_indices])\n",
        "train_loader_1 = torch.utils.data.DataLoader(train_dataset_1, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader_1 = torch.utils.data.DataLoader(test_dataset_1, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "lYSmxReU03aR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_indices = [2,3]\n",
        "train_dataset_2 = torch.utils.data.Subset(train_dataset, [i for i in range(len(train_dataset)) if train_dataset.targets[i] in class_indices])\n",
        "test_dataset_2 = torch.utils.data.Subset(train_dataset, [i for i in range(len(train_dataset)) if train_dataset.targets[i] in class_indices])\n",
        "train_loader_2 = torch.utils.data.DataLoader(train_dataset_2, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader_2 = torch.utils.data.DataLoader(test_dataset_2, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "fHb1EV8Y05AC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(model1.parameters(), lr=0.001)\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "M2MdlPFx06rY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model1.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader_1:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model1(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader_1)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7Idq1Fo08uA",
        "outputId": "57e523a4-ce3e-4397-cbb8-9a9eb1c8fcdb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Loss: 0.1851\n",
            "Epoch [2/10] Loss: 0.0880\n",
            "Epoch [3/10] Loss: 0.0532\n",
            "Epoch [4/10] Loss: 0.0369\n",
            "Epoch [5/10] Loss: 0.0402\n",
            "Epoch [6/10] Loss: 0.0311\n",
            "Epoch [7/10] Loss: 0.1527\n",
            "Epoch [8/10] Loss: 0.0619\n",
            "Epoch [9/10] Loss: 0.0357\n",
            "Epoch [10/10] Loss: 0.0243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader_1:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model1(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct_predictions / total_samples\n",
        "print(f'Accuracy : {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNqf5ftZ0-Xd",
        "outputId": "18461c09-0d79-43c1-ffef-1032e5cc3d3e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 99.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = ResNet50(hidden_units=128, out_size=4).to(device)"
      ],
      "metadata": {
        "id": "pw8hNNmv1GvL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model2.parameters(), lr=0.001)\n",
        "num_epochs = 15"
      ],
      "metadata": {
        "id": "7kXarmpK1Jfl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.eval()\n",
        "kl_criterion = nn.KLDivLoss(reduction='batchmean').to(device)\n",
        "ce_criterion = nn.CrossEntropyLoss().to(device)\n",
        "alpha = 0.5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model2.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader_2:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        labels = labels % 2\n",
        "        optimizer.zero_grad()\n",
        "        with torch.no_grad():\n",
        "            teacher_outputs = model1(inputs)\n",
        "            zeros_tensor = torch.zeros_like(teacher_outputs)\n",
        "            teacher_outputs = torch.cat((teacher_outputs, zeros_tensor), dim=1)\n",
        "\n",
        "        outputs = model2(inputs)\n",
        "\n",
        "        kl_loss = kl_criterion(torch.log_softmax(outputs, dim=1), torch.softmax(teacher_outputs, dim=1))\n",
        "        ce_loss = ce_criterion(outputs, labels)\n",
        "        loss = alpha * ce_loss + (1-alpha) * kl_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader_2)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni-RRKPp1MBC",
        "outputId": "c1b7eeb9-7e49-4bd6-8837-87a777704435"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15] Loss: 0.5745\n",
            "Epoch [2/15] Loss: 0.5254\n",
            "Epoch [3/15] Loss: 0.5015\n",
            "Epoch [4/15] Loss: 0.4581\n",
            "Epoch [5/15] Loss: 0.4352\n",
            "Epoch [6/15] Loss: 0.4179\n",
            "Epoch [7/15] Loss: 0.4073\n",
            "Epoch [8/15] Loss: 0.4064\n",
            "Epoch [9/15] Loss: 0.3956\n",
            "Epoch [10/15] Loss: 0.3856\n",
            "Epoch [11/15] Loss: 0.3821\n",
            "Epoch [12/15] Loss: 0.3771\n",
            "Epoch [13/15] Loss: 0.3699\n",
            "Epoch [14/15] Loss: 0.3707\n",
            "Epoch [15/15] Loss: 0.3706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader_2:\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        outputs = model2(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        correct_predictions += (predicted == labels % 2).sum().item()\n",
        "\n",
        "accuracy = 100 * correct_predictions / total_samples\n",
        "print(f'Accuracy : {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNPXiqTy1UFy",
        "outputId": "29dc9cd9-76bc-4d5f-e9b1-5c7bbeabb3e9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 95.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader_1:\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        outputs = model2(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct_predictions / total_samples\n",
        "print(f'Accuracy : {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_nkp9f81W_C",
        "outputId": "2f5a07da-8258-4d56-a2a8-ecf1aaee44af"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 78.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QbmT5Czt1YhP"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}